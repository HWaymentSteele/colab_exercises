{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPKnZDKyDZmhzYoIj3hR8de",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HWaymentSteele/colab_exercises/blob/main/BIOC241_GA_GB_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BIOC 241 Macromolecules exercise 1\n",
        "\n",
        "Can AF2 correctly predict the structures of the GA88/GB88 proteins?\n",
        "\n",
        "Also: meet a codebase where it's easier to hack AlphaFold.\n",
        "\n",
        "\n",
        "- Hit the (play) button to the left to run a cell.\n",
        "\n",
        "- Questions to answer for the session are in **bold**.\n",
        "\n",
        "\n",
        "<font size=\"2\"><font color='gray'>Codebase: [ColabDesign](https://github.com/sokrypton/ColabDesign/tree/main) (gamma branch) by Sergey Ovchinnikov\n",
        "\n",
        "<font size=\"2\"><font color='gray'>Notebook last updated Sept 15 2023, Hannah Wayment-Steele\n"
      ],
      "metadata": {
        "id": "1B_WrMvF-8EV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6nujZb4DP91",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#@title setup\n",
        "\n",
        "import os, time, gc\n",
        "if not os.path.isdir(\"params\"):\n",
        "  # get code\n",
        "  print(\"installing ColabDesign\")\n",
        "  os.system(\"(mkdir params; apt-get install aria2 -qq; \\\n",
        "  aria2c -q -x 16 https://storage.googleapis.com/alphafold/alphafold_params_2022-12-06.tar; \\\n",
        "  tar -xf alphafold_params_2022-12-06.tar -C params; touch params/done.txt )&\")\n",
        "\n",
        "  os.system(\"pip -q install git+https://github.com/sokrypton/ColabDesign.git@gamma\")\n",
        "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/colabdesign colabdesign\")\n",
        "  os.system(\"wget https://raw.githubusercontent.com/sokrypton/ColabFold/beta/colabfold/mmseqs/api.py\")\n",
        "\n",
        "  # install hhsuite\n",
        "  print(\"installing HHsuite\")\n",
        "  os.makedirs(\"hhsuite\", exist_ok=True)\n",
        "  os.system(f\"curl -fsSL https://github.com/soedinglab/hh-suite/releases/download/v3.3.0/hhsuite-3.3.0-SSE2-Linux.tar.gz | tar xz -C hhsuite/\")\n",
        "\n",
        "  # download params\n",
        "  if not os.path.isfile(\"params/done.txt\"):\n",
        "    print(\"downloading AlphaFold params\")\n",
        "    while not os.path.isfile(\"params/done.txt\"):\n",
        "      time.sleep(5)\n",
        "if \"hhsuite\" not in os.environ['PATH']:\n",
        "  os.environ['PATH'] += \":hhsuite/bin:hhsuite/scripts\"\n",
        "\n",
        "import re, tempfile\n",
        "from IPython.display import HTML\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "from colabdesign import mk_af_model, clear_mem\n",
        "from colabdesign.af.contrib import predict\n",
        "from colabdesign.shared.protein import _np_rmsd\n",
        "from colabdesign.shared.parsers import aa2num\n",
        "from copy import copy\n",
        "\n",
        "from api import run_mmseqs2\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import numpy as np\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "def one_hot(x,cat=None):\n",
        "  if cat is None: cat = np.max(x)+1\n",
        "  oh = np.concatenate((np.eye(cat),np.zeros([1,cat])))\n",
        "  return oh[x]\n",
        "\n",
        "def run_hhalign(query_sequence, target_sequence, query_a3m=None, target_a3m=None):\n",
        "  with tempfile.NamedTemporaryFile() as tmp_query, \\\n",
        "  tempfile.NamedTemporaryFile() as tmp_target, \\\n",
        "  tempfile.NamedTemporaryFile() as tmp_alignment:\n",
        "    if query_a3m is None:\n",
        "      tmp_query.write(f\">Q\\n{query_sequence}\\n\".encode())\n",
        "      tmp_query.flush()\n",
        "      query_a3m = tmp_query.name\n",
        "    if target_a3m is None:\n",
        "      tmp_target.write(f\">T\\n{target_sequence}\\n\".encode())\n",
        "      tmp_target.flush()\n",
        "      target_a3m = tmp_target.name\n",
        "    os.system(f\"hhalign -hide_cons -i {query_a3m} -t {target_a3m} -o {tmp_alignment.name}\")\n",
        "    X, start_indices = predict.parse_hhalign_output(tmp_alignment.name)\n",
        "  return X, start_indices\n",
        "\n",
        "def run_hhfilter(input, output, id=90, qid=10):\n",
        "  os.system(f\"hhfilter -id {id} -qid {qid} -i {input} -o {output}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. First let's predict the structure of GA88 and go through the building blocks of the ColabDesign code."
      ],
      "metadata": {
        "id": "RAy-nPy3_dZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we define our protein sequence as a string.\n",
        "name='GA88'\n",
        "seq='TTYKLILNLKQAKEEAIKELVDAGIAEKYIKLIANAKTVEGVWTLKDEILTFTVTE'\n",
        "\n",
        "#we'll first fetch the msa.\n",
        "msa, deletion_matrix = predict.get_msa(seq, name, max_msa=4096,\n",
        "        do_not_filter=True,\n",
        "        mmseqs2_fn=run_mmseqs2,\n",
        "        hhfilter_fn=run_hhfilter)"
      ],
      "metadata": {
        "id": "1OcusmNBDhDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In the MSA, let's visualize sequence identity to the query and coverage.\n",
        "predict.plot_msa(msa,[len(seq)])"
      ],
      "metadata": {
        "id": "wHFQMAFKAXwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's initialize AF2 and make a structure prediction using this MSA.\n",
        "\n",
        "Double click on the below cell to check out the AF2 model getting initialized and setting options.\n",
        "\n",
        "**What function is initializing the `af2` object?**\n",
        "\n",
        "After you've taken a look, execute the cell to run predictions with this MSA. (You can double click to hide the code again if you want.)\n",
        "\n",
        "Note: We're running AF2 with 0 recycles. This is something people do that lets us better evaluate the intrinsic predictive power of AF2. If you're familiar with how AF2 works, think about why.\n"
      ],
      "metadata": {
        "id": "eV_JcYT6B3yM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jobname = \"GA88\" #@param {type:\"string\"}\n",
        "model_type = \"auto\" #@param [\"monomer (ptm)\", \"multimer (v3)\", \"auto\"]\n",
        "model = \"all\" #@param [\"1\", \"2\", \"3\", \"4\", \"5\", \"all\"]\n",
        "num_recycles = 0 #@param [\"0\", \"1\", \"2\", \"3\", \"6\", \"12\", \"24\"] {type:\"raw\"}\n",
        "recycle_early_stop_tolerance = 0.0 #@param [\"0.0\", \"0.5\", \"1.0\"] {type:\"raw\"}\n",
        "use_initial_guess = False\n",
        "#@markdown MSA options\n",
        "num_msa = 512 #@param [\"1\",\"2\",\"4\",\"8\",\"16\",\"32\", \"64\", \"128\", \"256\", \"512\"] {type:\"raw\"}\n",
        "num_extra_msa = 1 #@param [\"1\",\"2\",\"4\",\"8\",\"16\",\"32\", \"64\", \"128\", \"256\", \"512\", \"1024\",\"2048\",\"4096\"] {type:\"raw\"}\n",
        "#@markdown Stochastic options\n",
        "use_dropout = False #@param {type:\"boolean\"}\n",
        "seed = 0 #@param {type:\"raw\"}\n",
        "num_seeds = 1 #@param [\"1\", \"2\", \"4\", \"8\", \"16\", \"32\", \"64\", \"128\"] {type:\"raw\"}\n",
        "batches = [None]\n",
        "copies=1\n",
        "use_templates=False\n",
        "u_lengths=[len(seq)]\n",
        "use_mlm=False\n",
        "\n",
        "if model_type == \"monomer (ptm)\":\n",
        "  use_multimer = False\n",
        "elif model_type == \"multimer (v3)\":\n",
        "  use_multimer = True\n",
        "elif len(u_lengths) > 1 or copies > 1:\n",
        "  use_multimer = True\n",
        "else:\n",
        "  use_multimer = False\n",
        "\n",
        "model_opts = {\"num_msa\":num_msa, # number of sequences to use\n",
        "              \"num_extra_msa\":num_extra_msa,\n",
        "              \"num_templates\":len(batches),\n",
        "              \"use_mlm\":use_mlm,\n",
        "              \"use_cluster_profile\":False,\n",
        "              \"use_multimer\":use_multimer,\n",
        "              \"use_templates\":use_templates,\n",
        "              \"use_batch_as_template\":False,\n",
        "              \"use_dgram\":True,\n",
        "              \"protocol\":\"hallucination\",\n",
        "              \"best_metric\":\"pae\",\n",
        "              \"optimize_seq\":False,\n",
        "              \"debug\":False,\n",
        "              \"clear_prev\":False}\n",
        "\n",
        "if \"af\" in dir():\n",
        "  if model_opts != model_opts_:\n",
        "    if model_opts[\"use_multimer\"] == af._args[\"use_multimer\"] \\\n",
        "    or model_opts[\"use_templates\"] == af._args[\"use_templates\"]:\n",
        "      old_params = dict(zip(af._model_names,\n",
        "                            af._model_params))\n",
        "    else:\n",
        "      print(\"loading alphafold params\")\n",
        "      old_params = {}\n",
        "    af = mk_af_model(old_params=old_params,\n",
        "                     **model_opts)\n",
        "    model_opts_ = predict.copy_dict(model_opts)\n",
        "else:\n",
        "  print(\"loading alphafold params\")\n",
        "  af = mk_af_model(**model_opts)\n",
        "  model_opts_ = predict.copy_dict(model_opts)\n",
        "\n",
        "run_opts = {\"seed\":seed,\n",
        "            \"use_mlm\":use_mlm,\n",
        "            \"use_dropout\":use_dropout,\n",
        "            \"num_recycles\":num_recycles,\n",
        "            \"model\":model,\n",
        "            \"use_initial_guess\":use_initial_guess}\n",
        "\n",
        "af.prep_inputs(u_lengths, copies=copies, seed=seed)\n",
        "\n",
        "if use_templates:\n",
        "  af.set_opt(use_initial_guess=use_initial_guess)\n",
        "  for n,batch in enumerate(batches):\n",
        "    af.set_template(batch=batch, n=n)\n",
        "  af.set_opt(\"template\",\n",
        "             rm_sc=rm_sidechain,\n",
        "             rm_seq=rm_sequence,\n",
        "             rm_ic=rm_interchain)\n",
        "af.set_opt(\"mlm\",\n",
        "           replace_fraction=0.15 if use_mlm else 0.0)\n",
        "\n",
        "if model == \"all\":\n",
        "  models = af._model_names\n",
        "else:\n",
        "  models = [af._model_names[int(model) - 1]]\n",
        "\n",
        "pdb_path = f\"{jobname}/pdb\"\n",
        "os.makedirs(pdb_path, exist_ok=True)\n",
        "\n",
        "seeds = list(range(seed,seed+num_seeds))\n",
        "print(\"running prediction\")\n",
        "\n",
        "outputs=[]\n",
        "\n",
        "af.set_msa(msa, deletion_matrix)\n",
        "\n",
        "for seed in seeds:\n",
        "  af.set_seed(seed)\n",
        "  for model in models:\n",
        "    o={}\n",
        "    recycle = 0\n",
        "    af._inputs.pop(\"prev\",None)\n",
        "    stop_recycle = False\n",
        "    while recycle < num_recycles + 1:\n",
        "      af.predict(dropout=use_dropout, models=[model], verbose=False)\n",
        "\n",
        "      print_str = f\"{name} seed={seed} model={model} recycle={recycle}\"\n",
        "      print_key = [\"plddt\",\"ptm\"]\n",
        "      if len(af._lengths) > 1: print_key.append(\"i_ptm\")\n",
        "      for k in print_key:\n",
        "        print_str += f\" {k}={af.aux['log'][k]:.3f}\"\n",
        "\n",
        "      af._inputs[\"prev\"] = af.aux[\"prev\"]\n",
        "      af._save_results(save_best=True, verbose=False)\n",
        "      af._k += 1\n",
        "\n",
        "      output_pdb = f\"{pdb_path}/{name}_{model}_seed{seed}.pdb\"\n",
        "      af.save_current_pdb(output_pdb)\n",
        "\n",
        "      recycle += 1\n",
        "      if recycle > 1:\n",
        "        rmsd_tol = _np_rmsd(af._tmp[\"traj\"][\"xyz\"][-2],\n",
        "                            af._tmp[\"traj\"][\"xyz\"][-1],\n",
        "                            use_jax=False)\n",
        "        if rmsd_tol < recycle_early_stop_tolerance:\n",
        "          stop_recycle = True\n",
        "        print_str += f\" rmsd_tol={rmsd_tol:.3f}\"\n",
        "      print(print_str)\n",
        "      if stop_recycle: break\n",
        "\n",
        "    for k in print_key:\n",
        "      o.update({k: af.aux['log'][k]})\n",
        "\n",
        "    o.update({'pdb_path': output_pdb})\n",
        "    o.update({'model': model})\n",
        "    o.update({'name': name})\n",
        "    outputs.append(o)\n",
        "\n",
        "import pandas as pd\n",
        "outputs = pd.DataFrame.from_records(outputs)\n",
        "################\n",
        "print(\"GC\",gc.collect())"
      ],
      "metadata": {
        "cellView": "form",
        "id": "N3B_Zj0VNQ2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above code, we made a class that serves as our alphafold model. We can call `af.plot_pdb()` to plot the highest-scoring structure."
      ],
      "metadata": {
        "id": "PnfKF5vBG3eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "af.plot_pdb()"
      ],
      "metadata": {
        "id": "QF8wEJUrGPUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Did AF2 correctly predict the structure of GA88?**"
      ],
      "metadata": {
        "id": "K-VpQ8-0HfYh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's generate a MSA for GB88.\n",
        "\n",
        "**Do you notice anything in common about the sequence coverage in this MSA and the GA88 MSA?**"
      ],
      "metadata": {
        "id": "Yo1e5EOsKefu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name='GB88'\n",
        "seq='TTYKLILNLKQAKEEAITEAVDAGTAEKYFKLYANAKTVEGVWTYKDEIKTFTVTE'\n",
        "\n",
        "msa, deletion_matrix = predict.get_msa(seq, name, max_msa=4096,\n",
        "        do_not_filter=True,\n",
        "        mmseqs2_fn=run_mmseqs2,\n",
        "        hhfilter_fn=run_hhfilter)\n",
        "\n",
        "predict.plot_msa(msa,[len(seq)])"
      ],
      "metadata": {
        "id": "eDcrfzD0Ki-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's make predictions."
      ],
      "metadata": {
        "id": "n3glVUS-Lx06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jobname = \"GB88\" #@param {type:\"string\"}\n",
        "model_type = \"auto\" #@param [\"monomer (ptm)\", \"multimer (v3)\", \"auto\"]\n",
        "model = \"all\" #@param [\"1\", \"2\", \"3\", \"4\", \"5\", \"all\"]\n",
        "num_recycles = 0 #@param [\"0\", \"1\", \"2\", \"3\", \"6\", \"12\", \"24\"] {type:\"raw\"}\n",
        "recycle_early_stop_tolerance = 0.0 #@param [\"0.0\", \"0.5\", \"1.0\"] {type:\"raw\"}\n",
        "use_initial_guess = False\n",
        "#@markdown MSA options\n",
        "num_msa = 512 #@param [\"1\",\"2\",\"4\",\"8\",\"16\",\"32\", \"64\", \"128\", \"256\", \"512\"] {type:\"raw\"}\n",
        "num_extra_msa = 1 #@param [\"1\",\"2\",\"4\",\"8\",\"16\",\"32\", \"64\", \"128\", \"256\", \"512\", \"1024\",\"2048\",\"4096\"] {type:\"raw\"}\n",
        "#@markdown Stochastic options\n",
        "use_dropout = False #@param {type:\"boolean\"}\n",
        "seed = 0 #@param {type:\"raw\"}\n",
        "num_seeds = 1 #@param [\"1\", \"2\", \"4\", \"8\", \"16\", \"32\", \"64\", \"128\"] {type:\"raw\"}\n",
        "batches = [None]\n",
        "copies=1\n",
        "use_templates=False\n",
        "u_lengths=[len(seq)]\n",
        "use_mlm=False\n",
        "\n",
        "if model_type == \"monomer (ptm)\":\n",
        "  use_multimer = False\n",
        "elif model_type == \"multimer (v3)\":\n",
        "  use_multimer = True\n",
        "elif len(u_lengths) > 1 or copies > 1:\n",
        "  use_multimer = True\n",
        "else:\n",
        "  use_multimer = False\n",
        "\n",
        "model_opts = {\"num_msa\":num_msa, # number of sequences to use\n",
        "              \"num_extra_msa\":num_extra_msa,\n",
        "              \"num_templates\":len(batches),\n",
        "              \"use_mlm\":use_mlm,\n",
        "              \"use_cluster_profile\":False,\n",
        "              \"use_multimer\":use_multimer,\n",
        "              \"use_templates\":use_templates,\n",
        "              \"use_batch_as_template\":False,\n",
        "              \"use_dgram\":True,\n",
        "              \"protocol\":\"hallucination\",\n",
        "              \"best_metric\":\"pae\",\n",
        "              \"optimize_seq\":False,\n",
        "              \"debug\":False,\n",
        "              \"clear_prev\":False}\n",
        "\n",
        "if \"af\" in dir():\n",
        "  if model_opts != model_opts_:\n",
        "    if model_opts[\"use_multimer\"] == af._args[\"use_multimer\"] \\\n",
        "    or model_opts[\"use_templates\"] == af._args[\"use_templates\"]:\n",
        "      old_params = dict(zip(af._model_names,\n",
        "                            af._model_params))\n",
        "    else:\n",
        "      print(\"loading alphafold params\")\n",
        "      old_params = {}\n",
        "    af = mk_af_model(old_params=old_params,\n",
        "                     **model_opts)\n",
        "    model_opts_ = predict.copy_dict(model_opts)\n",
        "else:\n",
        "  print(\"loading alphafold params\")\n",
        "  af = mk_af_model(**model_opts)\n",
        "  model_opts_ = predict.copy_dict(model_opts)\n",
        "\n",
        "run_opts = {\"seed\":seed,\n",
        "            \"use_mlm\":use_mlm,\n",
        "            \"use_dropout\":use_dropout,\n",
        "            \"num_recycles\":num_recycles,\n",
        "            \"model\":model,\n",
        "            \"use_initial_guess\":use_initial_guess}\n",
        "\n",
        "af.prep_inputs(u_lengths, copies=copies, seed=seed)\n",
        "\n",
        "if use_templates:\n",
        "  af.set_opt(use_initial_guess=use_initial_guess)\n",
        "  for n,batch in enumerate(batches):\n",
        "    af.set_template(batch=batch, n=n)\n",
        "  af.set_opt(\"template\",\n",
        "             rm_sc=rm_sidechain,\n",
        "             rm_seq=rm_sequence,\n",
        "             rm_ic=rm_interchain)\n",
        "af.set_opt(\"mlm\",\n",
        "           replace_fraction=0.15 if use_mlm else 0.0)\n",
        "\n",
        "if model == \"all\":\n",
        "  models = af._model_names\n",
        "else:\n",
        "  models = [af._model_names[int(model) - 1]]\n",
        "\n",
        "pdb_path = f\"{jobname}/pdb\"\n",
        "os.makedirs(pdb_path, exist_ok=True)\n",
        "\n",
        "seeds = list(range(seed,seed+num_seeds))\n",
        "print(\"running prediction\")\n",
        "\n",
        "outputs=[]\n",
        "\n",
        "af.set_msa(msa, deletion_matrix)\n",
        "\n",
        "for seed in seeds:\n",
        "  af.set_seed(seed)\n",
        "  for model in models:\n",
        "    o={}\n",
        "    recycle = 0\n",
        "    af._inputs.pop(\"prev\",None)\n",
        "    stop_recycle = False\n",
        "    while recycle < num_recycles + 1:\n",
        "      af.predict(dropout=use_dropout, models=[model], verbose=False)\n",
        "\n",
        "      print_str = f\"{name} seed={seed} model={model} recycle={recycle}\"\n",
        "      print_key = [\"plddt\",\"ptm\"]\n",
        "      if len(af._lengths) > 1: print_key.append(\"i_ptm\")\n",
        "      for k in print_key:\n",
        "        print_str += f\" {k}={af.aux['log'][k]:.3f}\"\n",
        "\n",
        "      af._inputs[\"prev\"] = af.aux[\"prev\"]\n",
        "      af._save_results(save_best=True, verbose=False)\n",
        "      af._k += 1\n",
        "\n",
        "      output_pdb = f\"{pdb_path}/{name}_{model}_seed{seed}.pdb\"\n",
        "      af.save_current_pdb(output_pdb)\n",
        "\n",
        "      recycle += 1\n",
        "      if recycle > 1:\n",
        "        rmsd_tol = _np_rmsd(af._tmp[\"traj\"][\"xyz\"][-2],\n",
        "                            af._tmp[\"traj\"][\"xyz\"][-1],\n",
        "                            use_jax=False)\n",
        "        if rmsd_tol < recycle_early_stop_tolerance:\n",
        "          stop_recycle = True\n",
        "        print_str += f\" rmsd_tol={rmsd_tol:.3f}\"\n",
        "      print(print_str)\n",
        "      if stop_recycle: break\n",
        "\n",
        "    for k in print_key:\n",
        "      o.update({k: af.aux['log'][k]})\n",
        "\n",
        "    o.update({'pdb_path': output_pdb})\n",
        "    o.update({'model': model})\n",
        "    o.update({'name': name})\n",
        "    outputs.append(o)\n",
        "\n",
        "import pandas as pd\n",
        "outputs = pd.DataFrame.from_records(outputs)\n",
        "################\n",
        "print(\"GC\",gc.collect())"
      ],
      "metadata": {
        "cellView": "form",
        "id": "axFJNtnXMFhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's check out the top-scoring model from GB88:\n",
        "\n",
        "af.plot_pdb()"
      ],
      "metadata": {
        "id": "zIwuCZcPMoUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Did AF2 correctly predict the structure of GB88?**\n",
        "\n",
        "Let's see what happens if we modify the GB88 MSA that we give AF2. We're going to use a filtering step to filter out sequences that are less similar to GB88. Below, the only change from before is that we're setting `do_not_filter=False`."
      ],
      "metadata": {
        "id": "CyYDhbP_MgtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name='GB88'\n",
        "seq='TTYKLILNLKQAKEEAITEAVDAGTAEKYFKLYANAKTVEGVWTYKDEIKTFTVTE'\n",
        "\n",
        "msa, deletion_matrix = predict.get_msa(seq, name, max_msa=4096,\n",
        "        do_not_filter=False,\n",
        "          id=99, #max sequence identity to query is 99\n",
        "          qid=60, # min sequence identity to query is 60\n",
        "        mmseqs2_fn=run_mmseqs2,\n",
        "        hhfilter_fn=run_hhfilter)\n",
        "\n",
        "predict.plot_msa(msa,[len(seq)])"
      ],
      "metadata": {
        "id": "0wXi-V1KLmW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How do you think predictions from this filtered MSA might change AF2's prediction for GB88? Why?**\n",
        "\n",
        "Let's give it a spin:"
      ],
      "metadata": {
        "id": "myygNHxtO_AL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jobname = \"GB88_filtered_MSA\" #@param {type:\"string\"}\n",
        "model_type = \"auto\" #@param [\"monomer (ptm)\", \"multimer (v3)\", \"auto\"]\n",
        "model = \"all\" #@param [\"1\", \"2\", \"3\", \"4\", \"5\", \"all\"]\n",
        "num_recycles = 0 #@param [\"0\", \"1\", \"2\", \"3\", \"6\", \"12\", \"24\"] {type:\"raw\"}\n",
        "recycle_early_stop_tolerance = 0.0 #@param [\"0.0\", \"0.5\", \"1.0\"] {type:\"raw\"}\n",
        "use_initial_guess = False\n",
        "#@markdown MSA options\n",
        "num_msa = 512 #@param [\"1\",\"2\",\"4\",\"8\",\"16\",\"32\", \"64\", \"128\", \"256\", \"512\"] {type:\"raw\"}\n",
        "num_extra_msa = 1 #@param [\"1\",\"2\",\"4\",\"8\",\"16\",\"32\", \"64\", \"128\", \"256\", \"512\", \"1024\",\"2048\",\"4096\"] {type:\"raw\"}\n",
        "#@markdown Stochastic options\n",
        "use_dropout = False #@param {type:\"boolean\"}\n",
        "seed = 0 #@param {type:\"raw\"}\n",
        "num_seeds = 1 #@param [\"1\", \"2\", \"4\", \"8\", \"16\", \"32\", \"64\", \"128\"] {type:\"raw\"}\n",
        "batches = [None]\n",
        "copies=1\n",
        "use_templates=False\n",
        "u_lengths=[len(seq)]\n",
        "use_mlm=False\n",
        "\n",
        "if model_type == \"monomer (ptm)\":\n",
        "  use_multimer = False\n",
        "elif model_type == \"multimer (v3)\":\n",
        "  use_multimer = True\n",
        "elif len(u_lengths) > 1 or copies > 1:\n",
        "  use_multimer = True\n",
        "else:\n",
        "  use_multimer = False\n",
        "\n",
        "model_opts = {\"num_msa\":num_msa, # number of sequences to use\n",
        "              \"num_extra_msa\":num_extra_msa,\n",
        "              \"num_templates\":len(batches),\n",
        "              \"use_mlm\":use_mlm,\n",
        "              \"use_cluster_profile\":False,\n",
        "              \"use_multimer\":use_multimer,\n",
        "              \"use_templates\":use_templates,\n",
        "              \"use_batch_as_template\":False,\n",
        "              \"use_dgram\":True,\n",
        "              \"protocol\":\"hallucination\",\n",
        "              \"best_metric\":\"pae\",\n",
        "              \"optimize_seq\":False,\n",
        "              \"debug\":False,\n",
        "              \"clear_prev\":False}\n",
        "\n",
        "if \"af\" in dir():\n",
        "  if model_opts != model_opts_:\n",
        "    if model_opts[\"use_multimer\"] == af._args[\"use_multimer\"] \\\n",
        "    or model_opts[\"use_templates\"] == af._args[\"use_templates\"]:\n",
        "      old_params = dict(zip(af._model_names,\n",
        "                            af._model_params))\n",
        "    else:\n",
        "      print(\"loading alphafold params\")\n",
        "      old_params = {}\n",
        "    af = mk_af_model(old_params=old_params,\n",
        "                     **model_opts)\n",
        "    model_opts_ = predict.copy_dict(model_opts)\n",
        "else:\n",
        "  print(\"loading alphafold params\")\n",
        "  af = mk_af_model(**model_opts)\n",
        "  model_opts_ = predict.copy_dict(model_opts)\n",
        "\n",
        "run_opts = {\"seed\":seed,\n",
        "            \"use_mlm\":use_mlm,\n",
        "            \"use_dropout\":use_dropout,\n",
        "            \"num_recycles\":num_recycles,\n",
        "            \"model\":model,\n",
        "            \"use_initial_guess\":use_initial_guess}\n",
        "\n",
        "af.prep_inputs(u_lengths, copies=copies, seed=seed)\n",
        "\n",
        "if use_templates:\n",
        "  af.set_opt(use_initial_guess=use_initial_guess)\n",
        "  for n,batch in enumerate(batches):\n",
        "    af.set_template(batch=batch, n=n)\n",
        "  af.set_opt(\"template\",\n",
        "             rm_sc=rm_sidechain,\n",
        "             rm_seq=rm_sequence,\n",
        "             rm_ic=rm_interchain)\n",
        "af.set_opt(\"mlm\",\n",
        "           replace_fraction=0.15 if use_mlm else 0.0)\n",
        "\n",
        "if model == \"all\":\n",
        "  models = af._model_names\n",
        "else:\n",
        "  models = [af._model_names[int(model) - 1]]\n",
        "\n",
        "pdb_path = f\"{jobname}/pdb\"\n",
        "os.makedirs(pdb_path, exist_ok=True)\n",
        "\n",
        "seeds = list(range(seed,seed+num_seeds))\n",
        "print(\"running prediction\")\n",
        "\n",
        "outputs=[]\n",
        "\n",
        "af.set_msa(msa, deletion_matrix)\n",
        "\n",
        "for seed in seeds:\n",
        "  af.set_seed(seed)\n",
        "  for model in models:\n",
        "    o={}\n",
        "    recycle = 0\n",
        "    af._inputs.pop(\"prev\",None)\n",
        "    stop_recycle = False\n",
        "    while recycle < num_recycles + 1:\n",
        "      af.predict(dropout=use_dropout, models=[model], verbose=False)\n",
        "\n",
        "      print_str = f\"{name} seed={seed} model={model} recycle={recycle}\"\n",
        "      print_key = [\"plddt\",\"ptm\"]\n",
        "      if len(af._lengths) > 1: print_key.append(\"i_ptm\")\n",
        "      for k in print_key:\n",
        "        print_str += f\" {k}={af.aux['log'][k]:.3f}\"\n",
        "\n",
        "      af._inputs[\"prev\"] = af.aux[\"prev\"]\n",
        "      af._save_results(save_best=True, verbose=False)\n",
        "      af._k += 1\n",
        "\n",
        "      output_pdb = f\"{pdb_path}/{name}_{model}_seed{seed}.pdb\"\n",
        "      af.save_current_pdb(output_pdb)\n",
        "\n",
        "      recycle += 1\n",
        "      if recycle > 1:\n",
        "        rmsd_tol = _np_rmsd(af._tmp[\"traj\"][\"xyz\"][-2],\n",
        "                            af._tmp[\"traj\"][\"xyz\"][-1],\n",
        "                            use_jax=False)\n",
        "        if rmsd_tol < recycle_early_stop_tolerance:\n",
        "          stop_recycle = True\n",
        "        print_str += f\" rmsd_tol={rmsd_tol:.3f}\"\n",
        "      print(print_str)\n",
        "      if stop_recycle: break\n",
        "\n",
        "    for k in print_key:\n",
        "      o.update({k: af.aux['log'][k]})\n",
        "\n",
        "    o.update({'pdb_path': output_pdb})\n",
        "    o.update({'model': model})\n",
        "    o.update({'name': name})\n",
        "    outputs.append(o)\n",
        "\n",
        "import pandas as pd\n",
        "outputs = pd.DataFrame.from_records(outputs)\n",
        "################\n",
        "print(\"GC\",gc.collect())"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9kcR7VECPSRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "af.plot_pdb()"
      ],
      "metadata": {
        "id": "-HKHjbvEIqdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Did AF2 correctly predict the structure of GB88 with the second MSA?**\n",
        "\n",
        "**Were you correct in your prediction about AF2?**"
      ],
      "metadata": {
        "id": "PI-co5g3QWH4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bonus: check out the other attributes of the `af` object. What does `af.animate()` do?\n",
        "\n",
        "For aficionados: this is the same object used in ColabDesign, so this is all the code one needs to try out protein design too! For our purposes here, we won't be using it in design mode (i.e., `optimize_seq=False`, and other things, to not do backprop). for more on ColabDesign, check out [this demo notebook](https://colab.research.google.com/github/sokrypton/ColabDesign/blob/v1.1.1/af/design.ipynb)."
      ],
      "metadata": {
        "id": "zEQqSznMK27r"
      }
    }
  ]
}