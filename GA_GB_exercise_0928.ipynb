{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HWaymentSteele/colab_exercises/blob/main/GA_GB_exercise_0928.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NMR school 2023, \"Interpreting AF2\" exercise\n",
        "\n",
        "Can AF2 correctly predict the structures of the GA88/GB88 proteins?\n",
        "\n",
        "Also: meet a codebase where it's easier to hack AlphaFold.\n",
        "\n",
        "\n",
        "- Hit the (play) button to the left to run a cell.\n",
        "\n",
        "- Questions to answer for the session are in **bold**.\n",
        "\n",
        "\n",
        "<font size=\"2\"><font color='gray'>Codebase: [ColabDesign](https://github.com/sokrypton/ColabDesign/tree/main) (gamma branch) by Sergey Ovchinnikov\n",
        "\n",
        "<font size=\"2\"><font color='gray'>Notebook last updated Sept 20 2023, Hannah Wayment-Steele\n"
      ],
      "metadata": {
        "id": "1B_WrMvF-8EV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G6nujZb4DP91",
        "cellView": "form",
        "outputId": "3650cc8b-c61f-4321-e2ba-5c24ced85e4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "installing ColabDesign\n",
            "installing HHsuite\n",
            "CPU times: user 1.38 s, sys: 866 ms, total: 2.24 s\n",
            "Wall time: 47 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#@title setup\n",
        "\n",
        "import os, time, gc\n",
        "if not os.path.isdir(\"params\"):\n",
        "  # get code\n",
        "  print(\"installing ColabDesign\")\n",
        "  os.system(\"(mkdir params; apt-get install aria2 -qq; \\\n",
        "  aria2c -q -x 16 https://storage.googleapis.com/alphafold/alphafold_params_2022-12-06.tar; \\\n",
        "  tar -xf alphafold_params_2022-12-06.tar -C params; touch params/done.txt )&\")\n",
        "\n",
        "  os.system(\"pip -q install git+https://github.com/sokrypton/ColabDesign.git@gamma\")\n",
        "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/colabdesign colabdesign\")\n",
        "  os.system(\"wget https://raw.githubusercontent.com/sokrypton/ColabFold/beta/colabfold/mmseqs/api.py\")\n",
        "\n",
        "  # install hhsuite\n",
        "  print(\"installing HHsuite\")\n",
        "  os.makedirs(\"hhsuite\", exist_ok=True)\n",
        "  os.system(f\"curl -fsSL https://github.com/soedinglab/hh-suite/releases/download/v3.3.0/hhsuite-3.3.0-SSE2-Linux.tar.gz | tar xz -C hhsuite/\")\n",
        "\n",
        "  # download params\n",
        "  if not os.path.isfile(\"params/done.txt\"):\n",
        "    print(\"downloading AlphaFold params\")\n",
        "    while not os.path.isfile(\"params/done.txt\"):\n",
        "      time.sleep(5)\n",
        "if \"hhsuite\" not in os.environ['PATH']:\n",
        "  os.environ['PATH'] += \":hhsuite/bin:hhsuite/scripts\"\n",
        "\n",
        "import re, tempfile\n",
        "from IPython.display import HTML\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "from colabdesign import mk_af_model, clear_mem\n",
        "from colabdesign.af.contrib import predict\n",
        "from colabdesign.shared.protein import _np_rmsd\n",
        "from colabdesign.shared.parsers import aa2num\n",
        "from copy import copy\n",
        "\n",
        "from api import run_mmseqs2\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import numpy as np\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "def one_hot(x,cat=None):\n",
        "  if cat is None: cat = np.max(x)+1\n",
        "  oh = np.concatenate((np.eye(cat),np.zeros([1,cat])))\n",
        "  return oh[x]\n",
        "\n",
        "def run_hhalign(query_sequence, target_sequence, query_a3m=None, target_a3m=None):\n",
        "  with tempfile.NamedTemporaryFile() as tmp_query, \\\n",
        "  tempfile.NamedTemporaryFile() as tmp_target, \\\n",
        "  tempfile.NamedTemporaryFile() as tmp_alignment:\n",
        "    if query_a3m is None:\n",
        "      tmp_query.write(f\">Q\\n{query_sequence}\\n\".encode())\n",
        "      tmp_query.flush()\n",
        "      query_a3m = tmp_query.name\n",
        "    if target_a3m is None:\n",
        "      tmp_target.write(f\">T\\n{target_sequence}\\n\".encode())\n",
        "      tmp_target.flush()\n",
        "      target_a3m = tmp_target.name\n",
        "    os.system(f\"hhalign -hide_cons -i {query_a3m} -t {target_a3m} -o {tmp_alignment.name}\")\n",
        "    X, start_indices = predict.parse_hhalign_output(tmp_alignment.name)\n",
        "  return X, start_indices\n",
        "\n",
        "def run_hhfilter(input, output, id=90, qid=10):\n",
        "  os.system(f\"hhfilter -id {id} -qid {qid} -i {input} -o {output}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. First let's predict the structure of GA88 and go through the building blocks of the ColabDesign code."
      ],
      "metadata": {
        "id": "RAy-nPy3_dZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we define our protein sequence as a string.\n",
        "name='GA88'\n",
        "seq='TTYKLILNLKQAKEEAIKELVDAGIAEKYIKLIANAKTVEGVWTLKDEILTFTVTE'\n",
        "\n",
        "#we'll first fetch the msa.\n",
        "msa, deletion_matrix = predict.get_msa(seq, name, max_msa=4096,\n",
        "        do_not_filter=True,\n",
        "        mmseqs2_fn=run_mmseqs2,\n",
        "        hhfilter_fn=run_hhfilter)"
      ],
      "metadata": {
        "id": "1OcusmNBDhDI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "806fba0c-95e9-47b7-f475-7321b14a4b82"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "getting unpaired MSA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "COMPLETE: 100%|██████████| 150/150 [elapsed: 00:01 remaining: 00:00]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "parsing msas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#In the MSA, let's visualize sequence identity to the query and coverage.\n",
        "predict.plot_msa(msa,[len(seq)])"
      ],
      "metadata": {
        "id": "wHFQMAFKAXwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's initialize AF2 and make a structure prediction using this MSA.\n",
        "\n",
        "Double click on the below cell to check out the AF2 model getting initialized and setting options.\n",
        "\n",
        "**What function is initializing the `af2` object?**\n",
        "\n",
        "After you've taken a look, execute the cell to run predictions with this MSA. (You can double click to hide the code again if you want.)\n",
        "\n",
        "Note: We're running AF2 with 0 recycles. This is something people do that lets us better evaluate the intrinsic predictive power of AF2. If you're familiar with how AF2 works, think about why.\n"
      ],
      "metadata": {
        "id": "eV_JcYT6B3yM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jobname = \"GA88\" #@param {type:\"string\"}\n",
        "model_type = \"auto\" #@param [\"monomer (ptm)\", \"multimer (v3)\", \"auto\"]\n",
        "model = \"all\" #@param [\"1\", \"2\", \"3\", \"4\", \"5\", \"all\"]\n",
        "num_recycles = 0 #@param [\"0\", \"1\", \"2\", \"3\", \"6\", \"12\", \"24\"] {type:\"raw\"}\n",
        "recycle_early_stop_tolerance = 0.0 #@param [\"0.0\", \"0.5\", \"1.0\"] {type:\"raw\"}\n",
        "use_initial_guess = False\n",
        "#@markdown MSA options\n",
        "num_msa = 512 #@param [\"1\",\"2\",\"4\",\"8\",\"16\",\"32\", \"64\", \"128\", \"256\", \"512\"] {type:\"raw\"}\n",
        "num_extra_msa = 1 #@param [\"1\",\"2\",\"4\",\"8\",\"16\",\"32\", \"64\", \"128\", \"256\", \"512\", \"1024\",\"2048\",\"4096\"] {type:\"raw\"}\n",
        "#@markdown Stochastic options\n",
        "use_dropout = False #@param {type:\"boolean\"}\n",
        "seed = 0 #@param {type:\"raw\"}\n",
        "num_seeds = 1 #@param [\"1\", \"2\", \"4\", \"8\", \"16\", \"32\", \"64\", \"128\"] {type:\"raw\"}\n",
        "batches = [None]\n",
        "copies=1\n",
        "use_templates=False\n",
        "u_lengths=[len(seq)]\n",
        "use_mlm=False\n",
        "\n",
        "if model_type == \"monomer (ptm)\":\n",
        "  use_multimer = False\n",
        "elif model_type == \"multimer (v3)\":\n",
        "  use_multimer = True\n",
        "elif len(u_lengths) > 1 or copies > 1:\n",
        "  use_multimer = True\n",
        "else:\n",
        "  use_multimer = False\n",
        "\n",
        "model_opts = {\"num_msa\":num_msa, # number of sequences to use\n",
        "              \"num_extra_msa\":num_extra_msa,\n",
        "              \"num_templates\":len(batches),\n",
        "              \"use_mlm\":use_mlm,\n",
        "              \"use_cluster_profile\":False,\n",
        "              \"use_multimer\":use_multimer,\n",
        "              \"use_templates\":use_templates,\n",
        "              \"use_batch_as_template\":False,\n",
        "              \"use_dgram\":True,\n",
        "              \"protocol\":\"hallucination\",\n",
        "              \"best_metric\":\"pae\",\n",
        "              \"optimize_seq\":False,\n",
        "              \"debug\":False,\n",
        "              \"clear_prev\":False}\n",
        "\n",
        "if \"af\" in dir():\n",
        "  if model_opts != model_opts_:\n",
        "    if model_opts[\"use_multimer\"] == af._args[\"use_multimer\"] \\\n",
        "    or model_opts[\"use_templates\"] == af._args[\"use_templates\"]:\n",
        "      old_params = dict(zip(af._model_names,\n",
        "                            af._model_params))\n",
        "    else:\n",
        "      print(\"loading alphafold params\")\n",
        "      old_params = {}\n",
        "    af = mk_af_model(old_params=old_params,\n",
        "                     **model_opts)\n",
        "    model_opts_ = predict.copy_dict(model_opts)\n",
        "else:\n",
        "  print(\"loading alphafold params\")\n",
        "  af = mk_af_model(**model_opts)\n",
        "  model_opts_ = predict.copy_dict(model_opts)\n",
        "\n",
        "run_opts = {\"seed\":seed,\n",
        "            \"use_mlm\":use_mlm,\n",
        "            \"use_dropout\":use_dropout,\n",
        "            \"num_recycles\":num_recycles,\n",
        "            \"model\":model,\n",
        "            \"use_initial_guess\":use_initial_guess}\n",
        "\n",
        "af.prep_inputs(u_lengths, copies=copies, seed=seed)\n",
        "\n",
        "if use_templates:\n",
        "  af.set_opt(use_initial_guess=use_initial_guess)\n",
        "  for n,batch in enumerate(batches):\n",
        "    af.set_template(batch=batch, n=n)\n",
        "  af.set_opt(\"template\",\n",
        "             rm_sc=rm_sidechain,\n",
        "             rm_seq=rm_sequence,\n",
        "             rm_ic=rm_interchain)\n",
        "af.set_opt(\"mlm\",\n",
        "           replace_fraction=0.15 if use_mlm else 0.0)\n",
        "\n",
        "if model == \"all\":\n",
        "  models = af._model_names\n",
        "else:\n",
        "  models = [af._model_names[int(model) - 1]]\n",
        "\n",
        "pdb_path = f\"{jobname}/pdb\"\n",
        "os.makedirs(pdb_path, exist_ok=True)\n",
        "\n",
        "seeds = list(range(seed,seed+num_seeds))\n",
        "print(\"running prediction\")\n",
        "\n",
        "outputs=[]\n",
        "\n",
        "af.set_msa(msa, deletion_matrix)\n",
        "\n",
        "for seed in seeds:\n",
        "  af.set_seed(seed)\n",
        "  for model in models:\n",
        "    o={}\n",
        "    recycle = 0\n",
        "    af._inputs.pop(\"prev\",None)\n",
        "    stop_recycle = False\n",
        "    while recycle < num_recycles + 1:\n",
        "      af.predict(dropout=use_dropout, models=[model], verbose=False)\n",
        "\n",
        "      print_str = f\"{name} seed={seed} model={model} recycle={recycle}\"\n",
        "      print_key = [\"plddt\",\"ptm\"]\n",
        "      if len(af._lengths) > 1: print_key.append(\"i_ptm\")\n",
        "      for k in print_key:\n",
        "        print_str += f\" {k}={af.aux['log'][k]:.3f}\"\n",
        "\n",
        "      af._inputs[\"prev\"] = af.aux[\"prev\"]\n",
        "      af._save_results(save_best=True, verbose=False)\n",
        "      af._k += 1\n",
        "\n",
        "      output_pdb = f\"{pdb_path}/{name}_{model}_seed{seed}.pdb\"\n",
        "      af.save_current_pdb(output_pdb)\n",
        "\n",
        "      recycle += 1\n",
        "      if recycle > 1:\n",
        "        rmsd_tol = _np_rmsd(af._tmp[\"traj\"][\"xyz\"][-2],\n",
        "                            af._tmp[\"traj\"][\"xyz\"][-1],\n",
        "                            use_jax=False)\n",
        "        if rmsd_tol < recycle_early_stop_tolerance:\n",
        "          stop_recycle = True\n",
        "        print_str += f\" rmsd_tol={rmsd_tol:.3f}\"\n",
        "      print(print_str)\n",
        "      if stop_recycle: break\n",
        "\n",
        "    for k in print_key:\n",
        "      o.update({k: af.aux['log'][k]})\n",
        "\n",
        "    o.update({'pdb_path': output_pdb})\n",
        "    o.update({'model': model})\n",
        "    o.update({'name': name})\n",
        "    outputs.append(o)\n",
        "\n",
        "import pandas as pd\n",
        "outputs = pd.DataFrame.from_records(outputs)\n",
        "################\n",
        "print(\"GC\",gc.collect())"
      ],
      "metadata": {
        "cellView": "form",
        "id": "N3B_Zj0VNQ2u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9294169e-e848-4900-d418-c984552f3c74"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading alphafold params\n",
            "running prediction\n",
            "GA88 seed=0 model=model_1_ptm recycle=0 plddt=0.839 ptm=0.577\n",
            "GA88 seed=0 model=model_2_ptm recycle=0 plddt=0.822 ptm=0.613\n",
            "GA88 seed=0 model=model_3_ptm recycle=0 plddt=0.826 ptm=0.586\n",
            "GA88 seed=0 model=model_4_ptm recycle=0 plddt=0.858 ptm=0.643\n",
            "GA88 seed=0 model=model_5_ptm recycle=0 plddt=0.821 ptm=0.592\n",
            "GC 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above code, we made a class that serves as our alphafold model. We can call `af.plot_pdb()` to plot the highest-scoring structure."
      ],
      "metadata": {
        "id": "PnfKF5vBG3eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "af.plot_pdb()"
      ],
      "metadata": {
        "id": "QF8wEJUrGPUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Did AF2 correctly predict the structure of GA88?**"
      ],
      "metadata": {
        "id": "K-VpQ8-0HfYh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's generate a MSA for GB88.\n",
        "\n",
        "**Do you notice anything in common about the sequence coverage in this MSA and the GA88 MSA?**"
      ],
      "metadata": {
        "id": "Yo1e5EOsKefu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name='GB88'\n",
        "seq='TTYKLILNLKQAKEEAITEAVDAGTAEKYFKLYANAKTVEGVWTYKDEIKTFTVTE'\n",
        "\n",
        "msa, deletion_matrix = predict.get_msa(seq, name, max_msa=4096,\n",
        "        do_not_filter=True,\n",
        "        mmseqs2_fn=run_mmseqs2,\n",
        "        hhfilter_fn=run_hhfilter)\n",
        "\n",
        "predict.plot_msa(msa,[len(seq)])"
      ],
      "metadata": {
        "id": "eDcrfzD0Ki-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's make predictions."
      ],
      "metadata": {
        "id": "n3glVUS-Lx06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jobname = \"GB88\" #@param {type:\"string\"}\n",
        "model_type = \"auto\" #@param [\"monomer (ptm)\", \"multimer (v3)\", \"auto\"]\n",
        "model = \"all\" #@param [\"1\", \"2\", \"3\", \"4\", \"5\", \"all\"]\n",
        "num_recycles = 0 #@param [\"0\", \"1\", \"2\", \"3\", \"6\", \"12\", \"24\"] {type:\"raw\"}\n",
        "recycle_early_stop_tolerance = 0.0 #@param [\"0.0\", \"0.5\", \"1.0\"] {type:\"raw\"}\n",
        "use_initial_guess = False\n",
        "#@markdown MSA options\n",
        "num_msa = 512 #@param [\"1\",\"2\",\"4\",\"8\",\"16\",\"32\", \"64\", \"128\", \"256\", \"512\"] {type:\"raw\"}\n",
        "num_extra_msa = 1 #@param [\"1\",\"2\",\"4\",\"8\",\"16\",\"32\", \"64\", \"128\", \"256\", \"512\", \"1024\",\"2048\",\"4096\"] {type:\"raw\"}\n",
        "#@markdown Stochastic options\n",
        "use_dropout = False #@param {type:\"boolean\"}\n",
        "seed = 0 #@param {type:\"raw\"}\n",
        "num_seeds = 1 #@param [\"1\", \"2\", \"4\", \"8\", \"16\", \"32\", \"64\", \"128\"] {type:\"raw\"}\n",
        "batches = [None]\n",
        "copies=1\n",
        "use_templates=False\n",
        "u_lengths=[len(seq)]\n",
        "use_mlm=False\n",
        "\n",
        "if model_type == \"monomer (ptm)\":\n",
        "  use_multimer = False\n",
        "elif model_type == \"multimer (v3)\":\n",
        "  use_multimer = True\n",
        "elif len(u_lengths) > 1 or copies > 1:\n",
        "  use_multimer = True\n",
        "else:\n",
        "  use_multimer = False\n",
        "\n",
        "model_opts = {\"num_msa\":num_msa, # number of sequences to use\n",
        "              \"num_extra_msa\":num_extra_msa,\n",
        "              \"num_templates\":len(batches),\n",
        "              \"use_mlm\":use_mlm,\n",
        "              \"use_cluster_profile\":False,\n",
        "              \"use_multimer\":use_multimer,\n",
        "              \"use_templates\":use_templates,\n",
        "              \"use_batch_as_template\":False,\n",
        "              \"use_dgram\":True,\n",
        "              \"protocol\":\"hallucination\",\n",
        "              \"best_metric\":\"pae\",\n",
        "              \"optimize_seq\":False,\n",
        "              \"debug\":False,\n",
        "              \"clear_prev\":False}\n",
        "\n",
        "if \"af\" in dir():\n",
        "  if model_opts != model_opts_:\n",
        "    if model_opts[\"use_multimer\"] == af._args[\"use_multimer\"] \\\n",
        "    or model_opts[\"use_templates\"] == af._args[\"use_templates\"]:\n",
        "      old_params = dict(zip(af._model_names,\n",
        "                            af._model_params))\n",
        "    else:\n",
        "      print(\"loading alphafold params\")\n",
        "      old_params = {}\n",
        "    af = mk_af_model(old_params=old_params,\n",
        "                     **model_opts)\n",
        "    model_opts_ = predict.copy_dict(model_opts)\n",
        "else:\n",
        "  print(\"loading alphafold params\")\n",
        "  af = mk_af_model(**model_opts)\n",
        "  model_opts_ = predict.copy_dict(model_opts)\n",
        "\n",
        "run_opts = {\"seed\":seed,\n",
        "            \"use_mlm\":use_mlm,\n",
        "            \"use_dropout\":use_dropout,\n",
        "            \"num_recycles\":num_recycles,\n",
        "            \"model\":model,\n",
        "            \"use_initial_guess\":use_initial_guess}\n",
        "\n",
        "af.prep_inputs(u_lengths, copies=copies, seed=seed)\n",
        "\n",
        "if use_templates:\n",
        "  af.set_opt(use_initial_guess=use_initial_guess)\n",
        "  for n,batch in enumerate(batches):\n",
        "    af.set_template(batch=batch, n=n)\n",
        "  af.set_opt(\"template\",\n",
        "             rm_sc=rm_sidechain,\n",
        "             rm_seq=rm_sequence,\n",
        "             rm_ic=rm_interchain)\n",
        "af.set_opt(\"mlm\",\n",
        "           replace_fraction=0.15 if use_mlm else 0.0)\n",
        "\n",
        "if model == \"all\":\n",
        "  models = af._model_names\n",
        "else:\n",
        "  models = [af._model_names[int(model) - 1]]\n",
        "\n",
        "pdb_path = f\"{jobname}/pdb\"\n",
        "os.makedirs(pdb_path, exist_ok=True)\n",
        "\n",
        "seeds = list(range(seed,seed+num_seeds))\n",
        "print(\"running prediction\")\n",
        "\n",
        "outputs=[]\n",
        "\n",
        "af.set_msa(msa, deletion_matrix)\n",
        "\n",
        "for seed in seeds:\n",
        "  af.set_seed(seed)\n",
        "  for model in models:\n",
        "    o={}\n",
        "    recycle = 0\n",
        "    af._inputs.pop(\"prev\",None)\n",
        "    stop_recycle = False\n",
        "    while recycle < num_recycles + 1:\n",
        "      af.predict(dropout=use_dropout, models=[model], verbose=False)\n",
        "\n",
        "      print_str = f\"{name} seed={seed} model={model} recycle={recycle}\"\n",
        "      print_key = [\"plddt\",\"ptm\"]\n",
        "      if len(af._lengths) > 1: print_key.append(\"i_ptm\")\n",
        "      for k in print_key:\n",
        "        print_str += f\" {k}={af.aux['log'][k]:.3f}\"\n",
        "\n",
        "      af._inputs[\"prev\"] = af.aux[\"prev\"]\n",
        "      af._save_results(save_best=True, verbose=False)\n",
        "      af._k += 1\n",
        "\n",
        "      output_pdb = f\"{pdb_path}/{name}_{model}_seed{seed}.pdb\"\n",
        "      af.save_current_pdb(output_pdb)\n",
        "\n",
        "      recycle += 1\n",
        "      if recycle > 1:\n",
        "        rmsd_tol = _np_rmsd(af._tmp[\"traj\"][\"xyz\"][-2],\n",
        "                            af._tmp[\"traj\"][\"xyz\"][-1],\n",
        "                            use_jax=False)\n",
        "        if rmsd_tol < recycle_early_stop_tolerance:\n",
        "          stop_recycle = True\n",
        "        print_str += f\" rmsd_tol={rmsd_tol:.3f}\"\n",
        "      print(print_str)\n",
        "      if stop_recycle: break\n",
        "\n",
        "    for k in print_key:\n",
        "      o.update({k: af.aux['log'][k]})\n",
        "\n",
        "    o.update({'pdb_path': output_pdb})\n",
        "    o.update({'model': model})\n",
        "    o.update({'name': name})\n",
        "    outputs.append(o)\n",
        "\n",
        "import pandas as pd\n",
        "outputs = pd.DataFrame.from_records(outputs)\n",
        "################\n",
        "print(\"GC\",gc.collect())"
      ],
      "metadata": {
        "cellView": "form",
        "id": "axFJNtnXMFhe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b31dfc24-71b5-4c0a-f303-461ce2767428"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running prediction\n",
            "GB88 seed=0 model=model_1_ptm recycle=0 plddt=0.614 ptm=0.422\n",
            "GB88 seed=0 model=model_2_ptm recycle=0 plddt=0.658 ptm=0.449\n",
            "GB88 seed=0 model=model_3_ptm recycle=0 plddt=0.636 ptm=0.428\n",
            "GB88 seed=0 model=model_4_ptm recycle=0 plddt=0.627 ptm=0.427\n",
            "GB88 seed=0 model=model_5_ptm recycle=0 plddt=0.524 ptm=0.341\n",
            "GC 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's check out the top-scoring model from GB88:\n",
        "\n",
        "af.plot_pdb()"
      ],
      "metadata": {
        "id": "zIwuCZcPMoUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Did AF2 correctly predict the structure of GB88?**\n",
        "\n",
        "Let's see what happens if we modify the GB88 MSA that we give AF2. We're going to use a filtering step to filter out sequences that are less similar to GB88. Below, the only change from before is that we're setting `do_not_filter=False`."
      ],
      "metadata": {
        "id": "CyYDhbP_MgtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name='GB88'\n",
        "seq='TTYKLILNLKQAKEEAITEAVDAGTAEKYFKLYANAKTVEGVWTYKDEIKTFTVTE'\n",
        "\n",
        "msa, deletion_matrix = predict.get_msa(seq, name, max_msa=4096,\n",
        "        do_not_filter=False,\n",
        "          id=99, #max sequence identity to query is 99\n",
        "          qid=60, # min sequence identity to query is 60\n",
        "        mmseqs2_fn=run_mmseqs2,\n",
        "        hhfilter_fn=run_hhfilter)\n",
        "\n",
        "predict.plot_msa(msa,[len(seq)])"
      ],
      "metadata": {
        "id": "0wXi-V1KLmW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How do you think predictions from this filtered MSA might change AF2's prediction for GB88? Why?**\n",
        "\n",
        "Let's give it a spin:"
      ],
      "metadata": {
        "id": "myygNHxtO_AL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jobname = \"GB88_filtered_MSA\" #@param {type:\"string\"}\n",
        "model_type = \"auto\" #@param [\"monomer (ptm)\", \"multimer (v3)\", \"auto\"]\n",
        "model = \"all\" #@param [\"1\", \"2\", \"3\", \"4\", \"5\", \"all\"]\n",
        "num_recycles = 0 #@param [\"0\", \"1\", \"2\", \"3\", \"6\", \"12\", \"24\"] {type:\"raw\"}\n",
        "recycle_early_stop_tolerance = 0.0 #@param [\"0.0\", \"0.5\", \"1.0\"] {type:\"raw\"}\n",
        "use_initial_guess = False\n",
        "#@markdown MSA options\n",
        "num_msa = 512 #@param [\"1\",\"2\",\"4\",\"8\",\"16\",\"32\", \"64\", \"128\", \"256\", \"512\"] {type:\"raw\"}\n",
        "num_extra_msa = 1 #@param [\"1\",\"2\",\"4\",\"8\",\"16\",\"32\", \"64\", \"128\", \"256\", \"512\", \"1024\",\"2048\",\"4096\"] {type:\"raw\"}\n",
        "#@markdown Stochastic options\n",
        "use_dropout = False #@param {type:\"boolean\"}\n",
        "seed = 0 #@param {type:\"raw\"}\n",
        "num_seeds = 1 #@param [\"1\", \"2\", \"4\", \"8\", \"16\", \"32\", \"64\", \"128\"] {type:\"raw\"}\n",
        "batches = [None]\n",
        "copies=1\n",
        "use_templates=False\n",
        "u_lengths=[len(seq)]\n",
        "use_mlm=False\n",
        "\n",
        "if model_type == \"monomer (ptm)\":\n",
        "  use_multimer = False\n",
        "elif model_type == \"multimer (v3)\":\n",
        "  use_multimer = True\n",
        "elif len(u_lengths) > 1 or copies > 1:\n",
        "  use_multimer = True\n",
        "else:\n",
        "  use_multimer = False\n",
        "\n",
        "model_opts = {\"num_msa\":num_msa, # number of sequences to use\n",
        "              \"num_extra_msa\":num_extra_msa,\n",
        "              \"num_templates\":len(batches),\n",
        "              \"use_mlm\":use_mlm,\n",
        "              \"use_cluster_profile\":False,\n",
        "              \"use_multimer\":use_multimer,\n",
        "              \"use_templates\":use_templates,\n",
        "              \"use_batch_as_template\":False,\n",
        "              \"use_dgram\":True,\n",
        "              \"protocol\":\"hallucination\",\n",
        "              \"best_metric\":\"pae\",\n",
        "              \"optimize_seq\":False,\n",
        "              \"debug\":False,\n",
        "              \"clear_prev\":False}\n",
        "\n",
        "if \"af\" in dir():\n",
        "  if model_opts != model_opts_:\n",
        "    if model_opts[\"use_multimer\"] == af._args[\"use_multimer\"] \\\n",
        "    or model_opts[\"use_templates\"] == af._args[\"use_templates\"]:\n",
        "      old_params = dict(zip(af._model_names,\n",
        "                            af._model_params))\n",
        "    else:\n",
        "      print(\"loading alphafold params\")\n",
        "      old_params = {}\n",
        "    af = mk_af_model(old_params=old_params,\n",
        "                     **model_opts)\n",
        "    model_opts_ = predict.copy_dict(model_opts)\n",
        "else:\n",
        "  print(\"loading alphafold params\")\n",
        "  af = mk_af_model(**model_opts)\n",
        "  model_opts_ = predict.copy_dict(model_opts)\n",
        "\n",
        "run_opts = {\"seed\":seed,\n",
        "            \"use_mlm\":use_mlm,\n",
        "            \"use_dropout\":use_dropout,\n",
        "            \"num_recycles\":num_recycles,\n",
        "            \"model\":model,\n",
        "            \"use_initial_guess\":use_initial_guess}\n",
        "\n",
        "af.prep_inputs(u_lengths, copies=copies, seed=seed)\n",
        "\n",
        "if use_templates:\n",
        "  af.set_opt(use_initial_guess=use_initial_guess)\n",
        "  for n,batch in enumerate(batches):\n",
        "    af.set_template(batch=batch, n=n)\n",
        "  af.set_opt(\"template\",\n",
        "             rm_sc=rm_sidechain,\n",
        "             rm_seq=rm_sequence,\n",
        "             rm_ic=rm_interchain)\n",
        "af.set_opt(\"mlm\",\n",
        "           replace_fraction=0.15 if use_mlm else 0.0)\n",
        "\n",
        "if model == \"all\":\n",
        "  models = af._model_names\n",
        "else:\n",
        "  models = [af._model_names[int(model) - 1]]\n",
        "\n",
        "pdb_path = f\"{jobname}/pdb\"\n",
        "os.makedirs(pdb_path, exist_ok=True)\n",
        "\n",
        "seeds = list(range(seed,seed+num_seeds))\n",
        "print(\"running prediction\")\n",
        "\n",
        "outputs=[]\n",
        "\n",
        "af.set_msa(msa, deletion_matrix)\n",
        "\n",
        "for seed in seeds:\n",
        "  af.set_seed(seed)\n",
        "  for model in models:\n",
        "    o={}\n",
        "    recycle = 0\n",
        "    af._inputs.pop(\"prev\",None)\n",
        "    stop_recycle = False\n",
        "    while recycle < num_recycles + 1:\n",
        "      af.predict(dropout=use_dropout, models=[model], verbose=False)\n",
        "\n",
        "      print_str = f\"{name} seed={seed} model={model} recycle={recycle}\"\n",
        "      print_key = [\"plddt\",\"ptm\"]\n",
        "      if len(af._lengths) > 1: print_key.append(\"i_ptm\")\n",
        "      for k in print_key:\n",
        "        print_str += f\" {k}={af.aux['log'][k]:.3f}\"\n",
        "\n",
        "      af._inputs[\"prev\"] = af.aux[\"prev\"]\n",
        "      af._save_results(save_best=True, verbose=False)\n",
        "      af._k += 1\n",
        "\n",
        "      output_pdb = f\"{pdb_path}/{name}_{model}_seed{seed}.pdb\"\n",
        "      af.save_current_pdb(output_pdb)\n",
        "\n",
        "      recycle += 1\n",
        "      if recycle > 1:\n",
        "        rmsd_tol = _np_rmsd(af._tmp[\"traj\"][\"xyz\"][-2],\n",
        "                            af._tmp[\"traj\"][\"xyz\"][-1],\n",
        "                            use_jax=False)\n",
        "        if rmsd_tol < recycle_early_stop_tolerance:\n",
        "          stop_recycle = True\n",
        "        print_str += f\" rmsd_tol={rmsd_tol:.3f}\"\n",
        "      print(print_str)\n",
        "      if stop_recycle: break\n",
        "\n",
        "    for k in print_key:\n",
        "      o.update({k: af.aux['log'][k]})\n",
        "\n",
        "    o.update({'pdb_path': output_pdb})\n",
        "    o.update({'model': model})\n",
        "    o.update({'name': name})\n",
        "    outputs.append(o)\n",
        "\n",
        "import pandas as pd\n",
        "outputs = pd.DataFrame.from_records(outputs)\n",
        "################\n",
        "print(\"GC\",gc.collect())"
      ],
      "metadata": {
        "id": "9kcR7VECPSRW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9d69f21-7ea3-4303-c992-cd7f902ba940",
        "cellView": "form"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running prediction\n",
            "GB88 seed=0 model=model_1_ptm recycle=0 plddt=0.590 ptm=0.412\n",
            "GB88 seed=0 model=model_2_ptm recycle=0 plddt=0.713 ptm=0.478\n",
            "GB88 seed=0 model=model_3_ptm recycle=0 plddt=0.623 ptm=0.418\n",
            "GB88 seed=0 model=model_4_ptm recycle=0 plddt=0.675 ptm=0.477\n",
            "GB88 seed=0 model=model_5_ptm recycle=0 plddt=0.552 ptm=0.375\n",
            "GC 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "af.plot_pdb()"
      ],
      "metadata": {
        "id": "-HKHjbvEIqdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Did AF2 correctly predict the structure of GB88 with the second MSA?**\n",
        "\n",
        "**Were you correct in your prediction about AF2?**"
      ],
      "metadata": {
        "id": "PI-co5g3QWH4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bonus: check out the other attributes of the `af` object. What does `af.animate()` do?\n",
        "\n",
        "For aficionados: this is the same object used in ColabDesign, so this is all the code one needs to try out protein design too! For our purposes here, we won't be using it in design mode (i.e., `optimize_seq=False`, and other things, to not do backprop). for more on ColabDesign, check out [this demo notebook](https://colab.research.google.com/github/sokrypton/ColabDesign/blob/v1.1.1/af/design.ipynb)."
      ],
      "metadata": {
        "id": "zEQqSznMK27r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part III: How well (or poorly) does pLDDT approximate thermodynamics in this system?\n",
        "\n",
        "In Alexander et al. (2009), the authors identify 6 sets of mutations between GA88 and GB88 that vary in their folds and stability, characterized by melting temperature. Notably, they find that only one point mutation can flip the structure!\n",
        "\n",
        "| Construct | Sequence | Fold | Tm (˚C) | dG @ 20˚C (kcal/mol) |\n",
        "| ---- |  ---- |  ---- |  ---- | ---- |\n",
        "|GA77 | `TTYKLILNLKQAKEEAIKELVDAGIAEKYIKLIANAKTVEGVWTLKDEILKATVTE` | GA | 77.5| 5 |\n",
        "|GA88 | `TTYKLILNLKQAKEEAIKELVDAGIAEKYIKLIANAKTVEGVWTLKDEILTFTVTE` | GA | 69.4| 4.9* |\n",
        "|GA91 | `TTYKLILNLKQAKEEAIKELVDAGTAEKYIKLIANAKTVEGVWTLKDEILTFTVTE` | GA | 61.5| >3 |\n",
        "|GA95 | `TTYKLILNLKQAKEEAIKELVDAGTAEKYIKLIANAKTVEGVWTLKDEIKTFTVTE` | GA | 50.0| 3 |\n",
        "|GA98 | `TTYKLILNLKQAKEEAIKELVDAGTAEKYFKLIANAKTVEGVWTLKDEIKTFTVTE` | GA | 37.0| 1.7* |\n",
        "|GB98 | `TTYKLILNLKQAKEEAIKELVDAGTAEKYFKLIANAKTVEGVWTYKDEIKTFTVTE` | GB | 35.0| 1.5* |\n",
        "|GB95 | `TTYKLILNLKQAKEEAIKEAVDAGTAEKYFKLIANAKTVEGVWTYKDEIKTFTVTE` | GB | 48.7| 3 |\n",
        "|GB91 | `TTYKLILNLKQAKEEAIKEAVDAGTAEKYFKLYANAKTVEGVWTYKDEIKTFTVTE` | GB | 49.3| >3 |\n",
        "|GB88 | `TTYKLILNLKQAKEEAITEAVDAGTAEKYFKLYANAKTVEGVWTYKDEIKTFTVTE` | GB | 57.5| 3.8* |\n",
        "|GB77 | `TTYKLILNGKQLKEEAITEAVDAATAEKYFKLYANAKTVEGVWTYKDETKTFTVTE` | GB | 62.4| 5 |\n",
        "\n",
        "*interpolated from reported values, assuming $\\Delta S_\\text{unfold}$ is constant.\n",
        "\n",
        "In this next part, we're going to explore how well (or poorly) AF2 predicts the folds of these structures, and the change in pLDDT predicts the measured changes in $\\Delta G$'s.\n",
        "\n",
        "---\n",
        "\n",
        "First we're going to create 2 MSAs, based on the WT GA and GB sequences, and use these as input to fold all the series of point mutations.\n"
      ],
      "metadata": {
        "id": "1S5r2UxbnVJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seqs = {\n",
        "'GA77':\t'TTYKLILNLKQAKEEAIKELVDAGIAEKYIKLIANAKTVEGVWTLKDEILKATVTE',\n",
        "'GA88':\t'TTYKLILNLKQAKEEAIKELVDAGIAEKYIKLIANAKTVEGVWTLKDEILTFTVTE',\n",
        "'GA91':\t'TTYKLILNLKQAKEEAIKELVDAGTAEKYIKLIANAKTVEGVWTLKDEILTFTVTE',\n",
        "'GA95':\t'TTYKLILNLKQAKEEAIKELVDAGTAEKYIKLIANAKTVEGVWTLKDEIKTFTVTE',\n",
        "'GA98':\t'TTYKLILNLKQAKEEAIKELVDAGTAEKYFKLIANAKTVEGVWTLKDEIKTFTVTE',\n",
        "'GB98':\t'TTYKLILNLKQAKEEAIKELVDAGTAEKYFKLIANAKTVEGVWTYKDEIKTFTVTE',\n",
        "'GB95':\t'TTYKLILNLKQAKEEAIKEAVDAGTAEKYFKLIANAKTVEGVWTYKDEIKTFTVTE',\n",
        "'GB91':\t'TTYKLILNLKQAKEEAIKEAVDAGTAEKYFKLYANAKTVEGVWTYKDEIKTFTVTE', # note there's a typo in Fig. 2 PNAS 2009.\n",
        "'GB88':\t'TTYKLILNLKQAKEEAITEAVDAGTAEKYFKLYANAKTVEGVWTYKDEIKTFTVTE',\n",
        "'GB77':\t'TTYKLILNGKQLKEEAITEAVDAATAEKYFKLYANAKTVEGVWTYKDETKTFTVTE',\n",
        "         }"
      ],
      "metadata": {
        "id": "DNxW39Bcm454"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First set up the af model again:"
      ],
      "metadata": {
        "id": "vaxRRRabEnu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jobname = \"GA_GB_mutant_series\" #@param {type:\"string\"}\n",
        "model_type = \"auto\" #@param [\"monomer (ptm)\", \"multimer (v3)\", \"auto\"]\n",
        "model = \"1\" #@param [\"1\", \"2\", \"3\", \"4\", \"5\", \"all\"]\n",
        "num_recycles = 0 #@param [\"0\", \"1\", \"2\", \"3\", \"6\", \"12\", \"24\"] {type:\"raw\"}\n",
        "recycle_early_stop_tolerance = 0.0 #@param [\"0.0\", \"0.5\", \"1.0\"] {type:\"raw\"}\n",
        "use_initial_guess = False\n",
        "#@markdown MSA options\n",
        "num_msa = 512 #@param [\"1\",\"2\",\"4\",\"8\",\"16\",\"32\", \"64\", \"128\", \"256\", \"512\"] {type:\"raw\"}\n",
        "num_extra_msa = 1 #@param [\"1\",\"2\",\"4\",\"8\",\"16\",\"32\", \"64\", \"128\", \"256\", \"512\", \"1024\",\"2048\",\"4096\"] {type:\"raw\"}\n",
        "#@markdown Stochastic options\n",
        "use_dropout = False #@param {type:\"boolean\"}\n",
        "seed = 0 #@param {type:\"raw\"}\n",
        "num_seeds = 1 #@param [\"1\", \"2\", \"4\", \"8\", \"16\", \"32\", \"64\", \"128\"] {type:\"raw\"}\n",
        "batches = [None]\n",
        "copies=1\n",
        "use_templates=False\n",
        "u_lengths=[len(seq)]\n",
        "use_mlm=False\n",
        "\n",
        "if model_type == \"monomer (ptm)\":\n",
        "  use_multimer = False\n",
        "elif model_type == \"multimer (v3)\":\n",
        "  use_multimer = True\n",
        "elif len(u_lengths) > 1 or copies > 1:\n",
        "  use_multimer = True\n",
        "else:\n",
        "  use_multimer = False\n",
        "\n",
        "model_opts = {\"num_msa\":num_msa, # number of sequences to use\n",
        "              \"num_extra_msa\":num_extra_msa,\n",
        "              \"num_templates\":len(batches),\n",
        "              \"use_mlm\":use_mlm,\n",
        "              \"use_cluster_profile\":False,\n",
        "              \"use_multimer\":use_multimer,\n",
        "              \"use_templates\":use_templates,\n",
        "              \"use_batch_as_template\":False,\n",
        "              \"use_dgram\":True,\n",
        "              \"protocol\":\"hallucination\",\n",
        "              \"best_metric\":\"pae\",\n",
        "              \"optimize_seq\":False,\n",
        "              \"debug\":False,\n",
        "              \"clear_prev\":False}\n",
        "\n",
        "if \"af\" in dir():\n",
        "  if model_opts != model_opts_:\n",
        "    if model_opts[\"use_multimer\"] == af._args[\"use_multimer\"] \\\n",
        "    or model_opts[\"use_templates\"] == af._args[\"use_templates\"]:\n",
        "      old_params = dict(zip(af._model_names,\n",
        "                            af._model_params))\n",
        "    else:\n",
        "      print(\"loading alphafold params\")\n",
        "      old_params = {}\n",
        "    af = mk_af_model(old_params=old_params,\n",
        "                     **model_opts)\n",
        "    model_opts_ = predict.copy_dict(model_opts)\n",
        "else:\n",
        "  print(\"loading alphafold params\")\n",
        "  af = mk_af_model(**model_opts)\n",
        "  model_opts_ = predict.copy_dict(model_opts)\n",
        "\n",
        "run_opts = {\"seed\":seed,\n",
        "            \"use_mlm\":use_mlm,\n",
        "            \"use_dropout\":use_dropout,\n",
        "            \"num_recycles\":num_recycles,\n",
        "            \"model\":model,\n",
        "            \"use_initial_guess\":use_initial_guess}\n",
        "\n",
        "af.prep_inputs(u_lengths, copies=copies, seed=seed)\n",
        "\n",
        "if use_templates:\n",
        "  af.set_opt(use_initial_guess=use_initial_guess)\n",
        "  for n,batch in enumerate(batches):\n",
        "    af.set_template(batch=batch, n=n)\n",
        "  af.set_opt(\"template\",\n",
        "             rm_sc=rm_sidechain,\n",
        "             rm_seq=rm_sequence,\n",
        "             rm_ic=rm_interchain)\n",
        "af.set_opt(\"mlm\",\n",
        "           replace_fraction=0.15 if use_mlm else 0.0)\n",
        "\n",
        "if model == \"all\":\n",
        "  models = af._model_names\n",
        "else:\n",
        "  models = [af._model_names[int(model) - 1]]\n",
        "\n",
        "pdb_path = f\"{jobname}/pdb\"\n",
        "os.makedirs(pdb_path, exist_ok=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kJGpWq45vzMp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fetch the msas:\n",
        "\n",
        "GA_WT='MEAVDANSLAQAKEAAIKELKQYGIGDYYIKLINNAKTVEGVESLKNEILKALPTE'\n",
        "GB_WT='MTYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDDATKTFTVTE'\n",
        "\n",
        "# Fetch the GA MSA:\n",
        "msa_A, dtx_A = predict.get_msa(GA_WT, 'GAWT', max_msa=4096,\n",
        "        do_not_filter=True,\n",
        "        mmseqs2_fn=run_mmseqs2,\n",
        "        hhfilter_fn=run_hhfilter)\n",
        "\n",
        "##### TODO: fetch the GB MSA #####\n",
        "\n",
        "##################################\n",
        "\n",
        "model=1\n",
        "seed=0\n",
        "outputs=[]\n",
        "\n",
        "##### TODO: Modify the below code to also loop through the GA and GB MSA #####\n",
        "\n",
        "for name, seq in seqs.items():\n",
        "  msa_list = [msa_A]\n",
        "  dtx_list = [dtx_A]\n",
        "  msa_names = ['GA_MSA']\n",
        "\n",
        "  for i in range(len(msa_list)):\n",
        "\n",
        "    local_msa = copy(msa_list[i])\n",
        "    local_msa[0] = aa2num(seq) # updates the first sequence to be the one we want.\n",
        "\n",
        "    af.set_msa(local_msa, dtx_list[i])\n",
        "    af.set_seed(seed)\n",
        "    o={}\n",
        "\n",
        "    recycle=0\n",
        "    af._inputs.pop(\"prev\",None)\n",
        "    stop_recycle = False\n",
        "    while recycle < num_recycles + 1:\n",
        "      af.predict(dropout=use_dropout, models=[model], verbose=False)\n",
        "\n",
        "      print_str = f\"MSA={msa_names[i]} {name} seed={seed} model={model} recycle={recycle}\"\n",
        "      print_key = [\"plddt\",\"ptm\"]\n",
        "      if len(af._lengths) > 1: print_key.append(\"i_ptm\")\n",
        "      for k in print_key:\n",
        "        print_str += f\" {k}={af.aux['log'][k]:.3f}\"\n",
        "\n",
        "      af._inputs[\"prev\"] = af.aux[\"prev\"]\n",
        "      af._save_results(save_best=True, verbose=False)\n",
        "      af._k += 1\n",
        "\n",
        "      output_pdb = f\"{pdb_path}/{msa_names[i]}_{name}_{model}_seed{seed}.pdb\"\n",
        "      af.save_current_pdb(output_pdb)\n",
        "\n",
        "      recycle += 1\n",
        "      if recycle > 1:\n",
        "        rmsd_tol = _np_rmsd(af._tmp[\"traj\"][\"xyz\"][-2],\n",
        "                            af._tmp[\"traj\"][\"xyz\"][-1],\n",
        "                            use_jax=False)\n",
        "        if rmsd_tol < recycle_early_stop_tolerance:\n",
        "          stop_recycle = True\n",
        "        print_str += f\" rmsd_tol={rmsd_tol:.3f}\"\n",
        "      print(print_str)\n",
        "      if stop_recycle: break\n",
        "\n",
        "    for k in print_key:\n",
        "      o.update({k: af.aux['log'][k]})\n",
        "\n",
        "    o.update({'MSA': msa_names[i]})\n",
        "    o.update({'sequence': name})\n",
        "    o.update({'exp_dG': dG[name]})\n",
        "    outputs.append(o)\n",
        "\n",
        "import pandas as pd\n",
        "outputs = pd.DataFrame.from_records(outputs)\n",
        "################\n",
        "print(\"GC\",gc.collect())"
      ],
      "metadata": {
        "id": "3Suld0P0nPQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.set_style('white')\n",
        "sns.set_context('paper')\n",
        "\n",
        "# the outputs of the runs is stored in a dataframe named \"outputs\". We're going to use it to check out the pLDDTs of the mutants.\n",
        "### Compare the pLDDTs for each variant using the MSA from both the GA and the GB MSA.\n",
        "### Google how to do a barplot in seaborn if you're not familiar."
      ],
      "metadata": {
        "id": "qWr4mlecvk6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discuss your results. Is this what you expect? Does the pLDDT for the correct structure mirror $\\Delta G(20˚C)$ ?\n",
        "\n",
        "---\n",
        "\n",
        "(response)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "XZHoFMOO0Pu4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uj1QJ8IfHQnY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}